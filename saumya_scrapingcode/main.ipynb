{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saumyasadhsaumya/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No statistics section found for Washington.\n",
      "No statistics section found for Oregon.\n",
      "Statistics table saved to scraped_data/CA_statistics.csv\n",
      "No statistics section found for Nevada.\n",
      "No statistics section found for Idaho.\n",
      "No statistics section found for Montana.\n",
      "No statistics section found for Wyoming.\n",
      "Statistics table saved to scraped_data/UT_statistics.csv\n",
      "No statistics section found for Arizona.\n",
      "No statistics section found for New Mexico.\n",
      "Statistics table saved to scraped_data/CO_statistics.csv\n",
      "No statistics section found for North Dakota.\n",
      "No statistics section found for South Dakota.\n",
      "Statistics table saved to scraped_data/NE_statistics.csv\n",
      "Statistics table saved to scraped_data/KS_statistics.csv\n",
      "Statistics table saved to scraped_data/OK_statistics.csv\n",
      "Statistics table saved to scraped_data/TX_statistics.csv\n",
      "No statistics section found for Minnesota.\n",
      "No statistics section found for Iowa.\n",
      "No statistics section found for Missouri.\n",
      "No statistics section found for Arkansas.\n",
      "No statistics section found for Louisiana.\n",
      "No statistics section found for Wisconsin.\n",
      "Statistics table saved to scraped_data/IL_statistics.csv\n",
      "No statistics section found for Indiana.\n",
      "No statistics section found for Michigan.\n",
      "No statistics section found for Ohio.\n",
      "No statistics section found for Kentucky.\n",
      "Statistics table saved to scraped_data/TN_statistics.csv\n",
      "No statistics section found for Mississippi.\n",
      "Statistics table saved to scraped_data/AL_statistics.csv\n",
      "No statistics section found for Georgia.\n",
      "Statistics table saved to scraped_data/FL_statistics.csv\n",
      "No statistics section found for South Carolina.\n",
      "No statistics section found for North Carolina.\n",
      "Statistics table saved to scraped_data/VA_statistics.csv\n",
      "No statistics section found for West Virginia.\n",
      "No statistics section found for Pennsylvania.\n",
      "No statistics section found for New York.\n",
      "No statistics section found for Vermont.\n",
      "No statistics section found for New Hampshire.\n",
      "No statistics section found for Maine.\n",
      "No statistics section found for Massachusetts.\n",
      "No statistics section found for Rhode Island.\n",
      "No statistics section found for Connecticut.\n",
      "No statistics section found for New Jersey.\n",
      "No statistics section found for Delaware.\n",
      "No statistics section found for Maryland.\n",
      "No statistics section found for District of Columbia.\n",
      "No statistics section found for Alaska.\n",
      "No statistics section found for Hawaii.\n",
      "No statistics section found for Guam.\n",
      "No statistics section found for Puerto Rico.\n",
      "No statistics section found for Virgin Islands.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import os \n",
    "\n",
    "static_url = \"https://www.ustatesloans.org/law/\"\n",
    "states = [\n",
    "    'WA', 'OR', 'CA', 'NV', 'ID', 'MT', 'WY', 'UT', 'AZ', 'NM', \n",
    "    'CO', 'ND', 'SD', 'NE', 'KS', 'OK', 'TX', 'MN', 'IA', 'MO', \n",
    "    'AR', 'LA', 'WI', 'IL', 'IN', 'MI', 'OH', 'KY', 'TN', 'MS', \n",
    "    'AL', 'GA', 'FL', 'SC', 'NC', 'VA', 'WV', 'PA', 'NY', 'VT', \n",
    "    'NH', 'ME', 'MA', 'RI', 'CT', 'NJ', 'DE', 'MD', 'DC', 'AK', \n",
    "    'HI', 'GU', 'PR', 'VI'\n",
    "] #list of states as seen in the url \n",
    "\n",
    "state_full_names = {\n",
    "    'WA': 'Washington', 'OR': 'Oregon', 'CA': 'California', 'NV': 'Nevada', \n",
    "    'ID': 'Idaho', 'MT': 'Montana', 'WY': 'Wyoming', 'UT': 'Utah', 'AZ': 'Arizona', \n",
    "    'NM': 'New Mexico', 'CO': 'Colorado', 'ND': 'North Dakota', 'SD': 'South Dakota', \n",
    "    'NE': 'Nebraska', 'KS': 'Kansas', 'OK': 'Oklahoma', 'TX': 'Texas', 'MN': 'Minnesota', \n",
    "    'IA': 'Iowa', 'MO': 'Missouri', 'AR': 'Arkansas', 'LA': 'Louisiana', 'WI': 'Wisconsin', \n",
    "    'IL': 'Illinois', 'IN': 'Indiana', 'MI': 'Michigan', 'OH': 'Ohio', 'KY': 'Kentucky', \n",
    "    'TN': 'Tennessee', 'MS': 'Mississippi', 'AL': 'Alabama', 'GA': 'Georgia', 'FL': 'Florida', \n",
    "    'SC': 'South Carolina', 'NC': 'North Carolina', 'VA': 'Virginia', 'WV': 'West Virginia', \n",
    "    'PA': 'Pennsylvania', 'NY': 'New York', 'VT': 'Vermont', 'NH': 'New Hampshire', \n",
    "    'ME': 'Maine', 'MA': 'Massachusetts', 'RI': 'Rhode Island', 'CT': 'Connecticut', \n",
    "    'NJ': 'New Jersey', 'DE': 'Delaware', 'MD': 'Maryland', 'DC': 'District of Columbia', \n",
    "    'AK': 'Alaska', 'HI': 'Hawaii', 'GU': 'Guam', 'PR': 'Puerto Rico', 'VI': 'Virgin Islands'\n",
    "} #mapping state code to full form, so it finds the right state on the website \n",
    "\n",
    "with open(\"payday_loan_data.txt\", \"w\") as file: #to store the text based result \n",
    "    for state in states:\n",
    "        state_name = state_full_names[state]\n",
    "        url = f\"{static_url}{state.lower()}/\"\n",
    "        response = requests.get(url)  #contruct the full URL and send GET request to fetch webpage for the state\n",
    "\n",
    "        if response.status_code == 200: #200 is what you should look for, if the request is sucessful, parses the HTML using beautifulsoup \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            file.write(f\"State: {state_name}\\n\")\n",
    "            file.write(\"=\" * 40 + \"\\n\") #writes the state's name and sperators line to the textfile \n",
    "\n",
    "            regulations_section = soup.find('div', class_='card mb-5') #find the div that contains payday loan regulations \n",
    "            if regulations_section:\n",
    "                file.write(\"\\nPayday Loan Regulations:\\n\")\n",
    "                rows = regulations_section.find_all('div', class_='row border-top') #If found, it loops through rows (<div class='row border-top'>), extracts key (e.g., \"Maximum Loan Amount\") and value (e.g., \"$700\").\n",
    "\n",
    "                for row in rows:\n",
    "                    key = row.find('strong')\n",
    "                    value = row.find('div', class_='col-md-7 py-1')\n",
    "                    if key and value:\n",
    "                        file.write(f\"{key.get_text(strip=True)}: {value.get_text(strip=True)}\\n\") #writes the regulations in text file \n",
    "            else:\n",
    "                file.write(\"No regulations section found.\\n\") \n",
    "\n",
    "            data_dir = \"scraped_data/\"\n",
    "\n",
    "            os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "            statistics_header = soup.find('h2', string=lambda text: text and \"Statistics\" in text) #to extract the statistics table, find header and extract statistics seciton\n",
    "            if statistics_header:\n",
    "                statistics_table = statistics_header.find_next('figure', class_='wp-block-table')\n",
    "                if statistics_table:\n",
    "                    csv_file_path = os.path.join(data_dir, f\"{state}_statistics.csv\")\n",
    "\n",
    "                    with open(csv_file_path, mode='w', newline='') as csv_file:\n",
    "                        csv_writer = csv.writer(csv_file)\n",
    "\n",
    "                        header_row = statistics_table.find('thead') #writes the table header in the CSV file \n",
    "                        if header_row:\n",
    "                            headers = [header.get_text(strip=True) for header in header_row.find_all('th')]\n",
    "                            csv_writer.writerow(headers)  \n",
    "\n",
    "                        rows = statistics_table.find_all('tr')\n",
    "                        for row in rows:\n",
    "                            columns = [col.get_text(strip=True) for col in row.find_all('td')]\n",
    "                            if columns:\n",
    "                                csv_writer.writerow(columns)\n",
    "\n",
    "                    print(f\"Statistics table saved to {csv_file_path}\")\n",
    "                else:\n",
    "                    print(f\"No statistics table found for {state_name}.\")\n",
    "            else:\n",
    "                print(f\"No statistics section found for {state_name}.\")\n",
    "\n",
    "            history_header = soup.find('h2', string=lambda text: text and \"The History of Payday Loans\" in text) #extract history of payday loan \n",
    "            if history_header:\n",
    "                file.write(\"\\nHistory of Payday Loans:\\n\")\n",
    "                \n",
    "                history_list = history_header.find_next('ul', class_='list-group wp-block-list')\n",
    "                if history_list:\n",
    "                    items = history_list.find_all('li')\n",
    "                    for item in items:\n",
    "                        date = item.find('strong')\n",
    "                        event = item.get_text(strip=True)\n",
    "                        if date:\n",
    "                            event = event.replace(date.get_text(strip=True), '').strip()\n",
    "                            file.write(f\"{date.get_text(strip=True)}: {event}\\n\")\n",
    "                        else:\n",
    "                            file.write(f\"- {event}\\n\")\n",
    "                else:\n",
    "                    file.write(\"No history content found.\\n\")\n",
    "            else:\n",
    "                file.write(f\"No history section found for {state_name}.\\n\")\n",
    "\n",
    "            file.write(\"\\n\" + \"=\" * 40 + \"\\n\\n\") #finalise the state data \n",
    "        else:\n",
    "            file.write(f\"Failed to fetch data for {state_name} (status code: {response.status_code})\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>No. of Stores</th>\n",
       "      <th>No. of Clients,million</th>\n",
       "      <th>No. of Loans,million</th>\n",
       "      <th>Value of Fees,million</th>\n",
       "      <th>Value of Loans,billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>2,144</td>\n",
       "      <td>1.6</td>\n",
       "      <td>12.1</td>\n",
       "      <td>–</td>\n",
       "      <td>$3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>2,119</td>\n",
       "      <td>1.7</td>\n",
       "      <td>12.4</td>\n",
       "      <td>–</td>\n",
       "      <td>$3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>2,100</td>\n",
       "      <td>1.8</td>\n",
       "      <td>12.3</td>\n",
       "      <td>–</td>\n",
       "      <td>$3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>2,058</td>\n",
       "      <td>1.8</td>\n",
       "      <td>12.2</td>\n",
       "      <td>–</td>\n",
       "      <td>$3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>2,014</td>\n",
       "      <td>1.8</td>\n",
       "      <td>12.4</td>\n",
       "      <td>–</td>\n",
       "      <td>$3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015</td>\n",
       "      <td>1,969</td>\n",
       "      <td>1.9</td>\n",
       "      <td>12.3</td>\n",
       "      <td>–</td>\n",
       "      <td>$4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>1,854</td>\n",
       "      <td>1.8</td>\n",
       "      <td>11.5</td>\n",
       "      <td>$467.2</td>\n",
       "      <td>$3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>1,705</td>\n",
       "      <td>1.7</td>\n",
       "      <td>10.7</td>\n",
       "      <td>$436.4</td>\n",
       "      <td>$2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018</td>\n",
       "      <td>1,645</td>\n",
       "      <td>1.6</td>\n",
       "      <td>10.2</td>\n",
       "      <td>$420.5</td>\n",
       "      <td>$2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019</td>\n",
       "      <td>1,551</td>\n",
       "      <td>1.6</td>\n",
       "      <td>10.2</td>\n",
       "      <td>$418.4</td>\n",
       "      <td>$2.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year No. of Stores  No. of Clients,million  No. of Loans,million  \\\n",
       "0  2010         2,144                     1.6                  12.1   \n",
       "1  2011         2,119                     1.7                  12.4   \n",
       "2  2012         2,100                     1.8                  12.3   \n",
       "3  2013         2,058                     1.8                  12.2   \n",
       "4  2014         2,014                     1.8                  12.4   \n",
       "5  2015         1,969                     1.9                  12.3   \n",
       "6  2016         1,854                     1.8                  11.5   \n",
       "7  2017         1,705                     1.7                  10.7   \n",
       "8  2018         1,645                     1.6                  10.2   \n",
       "9  2019         1,551                     1.6                  10.2   \n",
       "\n",
       "  Value of Fees,million Value of Loans,billion  \n",
       "0                     –                   $3.1  \n",
       "1                     –                   $3.3  \n",
       "2                     –                   $3.2  \n",
       "3                     –                   $3.2  \n",
       "4                     –                   $3.4  \n",
       "5                     –                   $4.2  \n",
       "6                $467.2                   $3.1  \n",
       "7                $436.4                   $2.9  \n",
       "8                $420.5                   $2.8  \n",
       "9                $418.4                   $2.8  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"scraped_data/CA_statistics.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
